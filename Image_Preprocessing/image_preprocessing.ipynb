{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_split(image_path: str) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Crops the center 150x150 region of an image and splits it into 9 smaller 50x50 images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : str\n",
    "        The file path to the image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[np.ndarray]\n",
    "        A list of 9 patches, each of size 50x50, extracted from the center cropped image.\n",
    "    \"\"\"\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(),  \n",
    "        transforms.CenterCrop(150) \n",
    "    ])\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    img = transform(img)\n",
    "\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    patches = []\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            patch = img_np[i*50:(i+1)*50, j*50:(j+1)*50]\n",
    "            patches.append(patch)\n",
    "    \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 50000/50000 [02:10<00:00, 381.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Path to ImageNet Large Scale Visual Recognizition Challenge 2012 Validation Set (ILSVRC 2012)\n",
    "folder_path = '/Users/wizard/Downloads/ILSVRC2012_img_val'\n",
    "\n",
    "# Matrix To Store All Entries\n",
    "img_mtrx = np.zeros((450000, 2500), dtype = np.float32)\n",
    "\n",
    "curr_idx = 0\n",
    "for i in tqdm(range(1, 50001), desc = 'Processing'):\n",
    "    path = os.path.join(folder_path, f'ILSVRC2012_val_{i:08d}.JPEG')\n",
    "\n",
    "    patches = crop_and_split(path)\n",
    "\n",
    "    for patch in patches:\n",
    "        img_mtrx[curr_idx] = patch.flatten()\n",
    "        curr_idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/wizard/Memory-Net-Inverse/Auxiliary_Functions/ILSVRC2012.pkl', 'wb') as f:\n",
    "    pickle.dump(img_mtrx, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
